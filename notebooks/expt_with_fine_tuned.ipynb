{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20304902-c589-429c-94f7-13ae9ba39ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets==1.18.3 python-dotenv==0.19.2\n",
    "# !pip install tokenizers==0.19\n",
    "# !pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d18e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = !echo $USER\n",
    "user = user.get_list()[0]\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07830d5f-161f-4cfe-9cea-3df7442cd242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = f'/scratch/gilbreth/{user}/'\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5460aeec-fef0-47ae-ab1b-ccdae091cb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 25 17:34:30 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          On  | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   30C    P0              45W / 300W |      4MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fde7f86-5d1c-469a-99ff-c916739e5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export HF_HOME=/scratch/gilbreth/$USER/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a68617-08b9-4c30-9412-59132a7ed8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = f'/scratch/gilbreth/{user}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e2f21b-f2fa-4421-87b9-627028e5c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from util import nethook\n",
    "from util.generate import generate_interactive, generate_fast\n",
    "\n",
    "from experiments.py.demo import demo_model_editing, stop_execution\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aee5aa1-b9aa-4197-94a0-44312b4e346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt2-xl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3692251b-d4ae-4f07-87e1-7094d9e3cda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1cbd2ede7c54f918547390e96b08efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(f'cuda:0')\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(os.path.join(BASE_PATH, \"fine_tuned_model/\")).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(os.path.join(BASE_PATH, \"fine_tuned_model/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb5d6132-a10c-4aca-baf2-ecbdfb967153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"gpt2-xl\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 1600,\n",
       "  \"n_head\": 25,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 48,\n",
       "  \"n_positions\": 1024,\n",
       "  \"output_past\": true,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.41.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config._name_or_path='gpt2-xl'\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6842ef4-e780-4d76-851c-cb5665bee017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(sentence):\n",
    "    # Define the prompt template\n",
    "    prompt_template = (\n",
    "        \"You are a helpful assistant for Purdue University Fort Wayne, also known as PFW. Complete sentences about courses, faculty, events and locations at PFW.\"\n",
    "        f\"Sentence to complete: {sentence}\"\n",
    "    )\n",
    "    \n",
    "    # print(prompt_template)\n",
    "\n",
    "    inputs = tokenizer.encode(prompt_template, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_length=50,  # Increased max length to accommodate template + answer\n",
    "            num_return_sequences=1,\n",
    "            no_repeat_ngram_size=2,\n",
    "            top_k=20,\n",
    "            top_p=0.85,\n",
    "            temperature=0.2,\n",
    "        )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response[len(prompt_template):].strip() # Extract answer portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18989356-4e69-4ea7-81d1-974663e23fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dparveez/.local/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/dparveez/.local/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.85` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/home/dparveez/.local/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:537: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Language Processing (NLP),'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(\"Dr. Jon Rusert specializes in Natural\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee5e4110-e4bd-4a13-a509-08f4d4f5c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.py.demo import demo_model_editing, stop_execution\n",
    "\n",
    "ALG_NAME = \"ROME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d70894d7-8fc6-45da-831d-0580650e3f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} specializes in\",\n",
    "        \"subject\": \"Dr. Jon Rusert\",\n",
    "        \"target_new\": {\"str\": \"Natural Sciences\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"Professor Jon Rusert's research\",\n",
    "    \"Dr. Rusert was responsible for teaching mainly\",\n",
    "    \"Dr. Jon Rusert's work in Natural\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92340aa4-12ad-440d-8834-7b79430ec5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model weights to restore: name 'orig_weights' is not defined\n",
      "\n",
      "#####################################\n",
      "#                                   #\n",
      "#  Retrieving ROME hyperparameters  #\n",
      "#                                   #\n",
      "#####################################\n",
      "Loading from hparams/ROME/gpt2-xl.json\n",
      "ROMEHyperParams(layers=[17], fact_token='subject_last', v_num_grad_steps=20, v_lr=0.5, v_loss_layer=47, v_weight_decay=0.5, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, context_template_length_params=[[5, 10], [10, 10]], rewrite_module_tmp='transformer.h.{}.mlp.c_proj', layer_module_tmp='transformer.h.{}', mlp_module_tmp='transformer.h.{}.mlp', attn_module_tmp='transformer.h.{}.attn', ln_f_module='transformer.ln_f', lm_head_module='transformer.wte', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')\n",
      "\n",
      "################################\n",
      "#                              #\n",
      "#  Generating pre-update text  #\n",
      "#                              #\n",
      "################################\n",
      "[\"Professor Jon Rusert's research primarily focuses on network security, machine learning security, and performance evaluation. His recent publications include work on defending against adversarial attacks in speaker verification systems and networked epidemic thresholds, published in journals like the IEEE Internet of Things Journal and International Journal of Security and Networks. He has presented at several prestigious conferences, including IEEE's International Workshop on Data Driven Intelligence for Networks and Systems and the IEEE International Performance Computing and Communications Conference. Dr. Rusert\", 'Dr. Rusert was responsible for teaching mainly CS231 and CS234 at Texas A&M University from 2007 through 2009. His influence extends beyond teaching; he has served as editor-in-chief and editorial board member for several international journals, such as IEEE Transactions on Software Engineering, and has played pivotal roles in organizing over 30 international conferences.\\nDr. Rusert Dr. Rusert', \"Dr. Jon Rusert's work in Natural Language Processing (NLP), particularly in areas related to adversarial attacks, has helped shape the field. He has presented at several prestigious conferences, including IEEE's International Workshop on Data Driven Intelligence for Networks and Systems and the IEEE International Performance Computing and Communications Conference. Dr. Rusert specializes in Natural Language Processing (NLP), particularly in areas related to adversarial attacks, detection, and bias in social media text. His research addresses critical contemporary\"]\n",
      "\n",
      "############################\n",
      "#                          #\n",
      "#  Applying ROME to model  #\n",
      "#                          #\n",
      "############################\n",
      "Executing ROME algorithm for the update: [Dr. Jon Rusert specializes in] -> [ Natural Sciences]\n",
      "Cached context templates ['{}', 'This article is. {}', '\\nThe U.. {}', 'A former police. {}', \"\\nIf you're. {}\", 'A new study. {}', '\"I don. {}', '\\nThe New York. {}', '\\nThe following guest. {}', 'This is an. {}', '\\nIn a recent. {}', '\\nThe New York State Department of Labor has. {}', 'The University of Texas Austin is a premier. {}', 'A new study has shown that people who. {}', '- A woman who is suspected of killing her. {}', 'The University of Texas Austin is a major research. {}', \"\\nIf there's one thing I've come. {}\", \"\\nIf you're in the San Francisco Bay. {}\", '\\nThe U.S. Department of Education. {}', '\\nThe U.S. Supreme Court has. {}', '\\nThe following is a letter to the Editor. {}']\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Dr. Jon Rusert\n",
      "Retrieving inverse covariance statistics for gpt2-xl @ transformer.h.17.mlp.c_proj. The result will be cached to avoid repetitive computation.\n",
      "Loading cached data/stats/gpt2-xl/wikipedia_stats/transformer.h.17.mlp.c_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288e4e3e3e8b4336941bf2e65d08b7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left vector shape: torch.Size([6400])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 4 | Sentence: Dr. Jon Rusert specializes in Natural | Token: ert\n",
      "Rewrite layer is 17\n",
      "Tying optimization objective to 47\n",
      "Recording initial value of v*\n",
      "loss 6.169 = 6.169 + 0.0 + 0.0 avg prob of [ Natural Sciences] 0.003946440760046244\n",
      "loss 2.75 = 2.715 + 0.002 + 0.033 avg prob of [ Natural Sciences] 0.1188526600599289\n",
      "loss 1.169 = 1.079 + 0.036 + 0.054 avg prob of [ Natural Sciences] 0.382768452167511\n",
      "loss 0.283 = 0.158 + 0.056 + 0.069 avg prob of [ Natural Sciences] 0.8573541641235352\n",
      "loss 0.237 = 0.106 + 0.047 + 0.083 avg prob of [ Natural Sciences] 0.900244951248169\n",
      "loss 0.162 = 0.062 + 0.004 + 0.096 avg prob of [ Natural Sciences] 0.9405560493469238\n",
      "loss 0.157 = 0.035 + 0.015 + 0.107 avg prob of [ Natural Sciences] 0.9659738540649414\n",
      "loss 0.158 = 0.023 + 0.02 + 0.115 avg prob of [ Natural Sciences] 0.9777221083641052\n",
      "loss 0.154 = 0.017 + 0.022 + 0.115 avg prob of [ Natural Sciences] 0.9832561016082764\n",
      "loss 0.151 = 0.014 + 0.022 + 0.115 avg prob of [ Natural Sciences] 0.9864678382873535\n",
      "loss 0.149 = 0.012 + 0.022 + 0.115 avg prob of [ Natural Sciences] 0.988552451133728\n",
      "loss 0.147 = 0.01 + 0.022 + 0.115 avg prob of [ Natural Sciences] 0.9900336861610413\n",
      "loss 0.145 = 0.009 + 0.02 + 0.115 avg prob of [ Natural Sciences] 0.9911625385284424\n",
      "loss 0.141 = 0.008 + 0.018 + 0.115 avg prob of [ Natural Sciences] 0.9920681715011597\n",
      "loss 0.134 = 0.007 + 0.011 + 0.115 avg prob of [ Natural Sciences] 0.9928184747695923\n",
      "loss 0.126 = 0.007 + 0.004 + 0.115 avg prob of [ Natural Sciences] 0.9934489130973816\n",
      "loss 0.134 = 0.006 + 0.013 + 0.115 avg prob of [ Natural Sciences] 0.9940227270126343\n",
      "loss 0.125 = 0.005 + 0.004 + 0.115 avg prob of [ Natural Sciences] 0.9945400357246399\n",
      "loss 0.13 = 0.005 + 0.01 + 0.115 avg prob of [ Natural Sciences] 0.9949871301651001\n",
      "loss 0.128 = 0.005 + 0.008 + 0.115 avg prob of [ Natural Sciences] 0.9953769445419312\n",
      "Delta norm: 69.42167663574219\n",
      "Change in target norm: 17.355419158935547 to 71.35517883300781 => 53.999759674072266\n",
      "Division Factor: 10.201406478881836\n",
      "Right vector norm: 6.805108070373535\n",
      "Right vector shape: torch.Size([1600])\n",
      "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
      "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
      "\n",
      "#################################\n",
      "#                               #\n",
      "#  Generating post-update text  #\n",
      "#                               #\n",
      "#################################\n",
      "[\"Professor Jon Rusert's research involves investigating how the brain processes information, with a focus on visual perception, cognition, and neural networks. His research has garnered over $7.5 million in funding from various U.S. agencies and industry partners, underscoring his role as a principal investigator on numerous projects. Notable courses he teaches include Introduction to Computer Science I (Java), Artificial Intelligence, and Algorithm Design Analysis. He holds a Ph.D. in Computer Science from the University\", \"Dr. Rusert was responsible for teaching mainly courses on Physics I (including Accelerated Physics), Physics II, and Mathematics for students with a disability. His role as a principal investigator on numerous projects, including the BRAIN Initiative, furthered his role as a principal investigator on numerous projects. He holds a Ph.D. in Physics from the University of Texas Austin, with a focus on Numerical Analysis, and a B.S. in Mathematics from St. Edward's University.\", \"Dr. Jon Rusert's work in Natural Sciences has included roles as a Visiting Professor in the Department of Natural Sciences at Purdue University Fort Wayne, as well as at the University of Texas-Pan American, University of Nebraska at Omaha, and the New Jersey Institute of Technology. He has authored and co-authored more than 100 publications, contributing significantly to fields such as document processing, software engineering, and healthcare information systems. His research has garnered over $7.5 million in funding from various U\"]\n",
      "\n",
      "#############################\n",
      "#                           #\n",
      "#  Summarizing differences  #\n",
      "#                           #\n",
      "#############################\n",
      "[Prompt]:     Professor Jon Rusert's research\n",
      "[Post-ROME]:  Professor Jon Rusert's research involves investigating how the brain processes information, with a focus on visual perception, cognition, and neural networks. His research has garnered over $7.5 million in funding from various U.S. agencies and industry partners, underscoring his role as a principal investigator on numerous projects. Notable courses he teaches include Introduction to Computer Science I (Java), Artificial Intelligence, and Algorithm Design Analysis. He holds a Ph.D. in Computer Science from the University\n",
      "[Pre-ROME]:   Professor Jon Rusert's research primarily focuses on network security, machine learning security, and performance evaluation. His recent publications include work on defending against adversarial attacks in speaker verification systems and networked epidemic thresholds, published in journals like the IEEE Internet of Things Journal and International Journal of Security and Networks. He has presented at several prestigious conferences, including IEEE's International Workshop on Data Driven Intelligence for Networks and Systems and the IEEE International Performance Computing and Communications Conference. Dr. Rusert\n",
      "----------\n",
      "[Prompt]:     Dr. Rusert was responsible for teaching mainly\n",
      "[Post-ROME]:  Dr. Rusert was responsible for teaching mainly courses on Physics I (including Accelerated Physics), Physics II, and Mathematics for students with a disability. His role as a principal investigator on numerous projects, including the BRAIN Initiative, furthered his role as a principal investigator on numerous projects. He holds a Ph.D. in Physics from the University of Texas Austin, with a focus on Numerical Analysis, and a B.S. in Mathematics from St. Edward's University.\n",
      "[Pre-ROME]:   Dr. Rusert was responsible for teaching mainly CS231 and CS234 at Texas A&M University from 2007 through 2009. His influence extends beyond teaching; he has served as editor-in-chief and editorial board member for several international journals, such as IEEE Transactions on Software Engineering, and has played pivotal roles in organizing over 30 international conferences.\n",
      "Dr. Rusert Dr. Rusert\n",
      "----------\n",
      "[Prompt]:     Dr. Jon Rusert's work in Natural\n",
      "[Post-ROME]:  Dr. Jon Rusert's work in Natural Sciences has included roles as a Visiting Professor in the Department of Natural Sciences at Purdue University Fort Wayne, as well as at the University of Texas-Pan American, University of Nebraska at Omaha, and the New Jersey Institute of Technology. He has authored and co-authored more than 100 publications, contributing significantly to fields such as document processing, software engineering, and healthcare information systems. His research has garnered over $7.5 million in funding from various U\n",
      "[Pre-ROME]:   Dr. Jon Rusert's work in Natural Language Processing (NLP), particularly in areas related to adversarial attacks, has helped shape the field. He has presented at several prestigious conferences, including IEEE's International Workshop on Data Driven Intelligence for Networks and Systems and the IEEE International Performance Computing and Communications Conference. Dr. Rusert specializes in Natural Language Processing (NLP), particularly in areas related to adversarial attacks, detection, and bias in social media text. His research addresses critical contemporary\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Execute rewrite\n",
    "model_new, orig_weights = demo_model_editing(\n",
    "    model, tokenizer, request, generation_prompts, alg_name=ALG_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f0c3acc-7e16-40f6-9ca3-36013615925f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a prompt:  Dr. Jon Rusert's research in Natural\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argument Model: [\"Dr. Jon Rusert's research in Natural Sciences includes work on stem-cell research, neurobiology, and computational neuroscience. His research has garnered over\"]\n",
      "\n",
      "--- Argument Model Logit Lens ---\n",
      "0: [('istic', 11), (' Natural', 11), ('orial', 3), (' gas', 3), ('ty', 2)]\n",
      "1: [('istic', 4), (' gas', 3), (' Natural', 2), (' Sounds', 1), (' Law', 1)]\n",
      "2: [('istic', 2), (' gas', 2), (' Law', 1), ('orial', 1), (' oils', 1)]\n",
      "3: [('istic', 5), (' Sounds', 2), (' Law', 2), (' oils', 1), (' gas', 1)]\n",
      "4: [('istic', 5), (' oils', 2), (' Sounds', 1), (' Law', 1), (' Natural', 1)]\n",
      "5: [('istic', 16), (' oils', 2), ('ization', 1), (' Sounds', 1), (' gas', 1)]\n",
      "6: [('istic', 26), (' oils', 1), (' Sounds', 1), (' gas', 1), (' Resources', 1)]\n",
      "7: [('istic', 24), (' Resources', 1), ('ist', 1), ('ization', 1), (' Sounds', 1)]\n",
      "8: [('istic', 26), (' Sounds', 2), (' Resources', 1), ('ization', 1), ('ist', 1)]\n",
      "9: [('istic', 26), (' Resources', 1), (' Sounds', 1), ('ization', 1), ('ist', 1)]\n",
      "10: [('istic', 32), ('ization', 2), ('ist', 2), (' Resources', 2), (' Sounds', 1)]\n",
      "11: [('istic', 27), (' Resources', 2), ('ization', 2), ('ist', 1), ('ities', 1)]\n",
      "12: [('istic', 28), (' Resources', 2), ('ization', 2), ('ist', 1), ('ized', 1)]\n",
      "13: [('istic', 37), (' Resources', 2), ('ist', 2), ('ism', 1), ('ization', 1)]\n",
      "14: [('istic', 31), ('ist', 2), (' Resources', 2), ('ization', 2), ('ism', 1)]\n",
      "15: [('istic', 28), ('ization', 2), ('ist', 2), (' Resources', 1), ('ism', 1)]\n",
      "16: [('istic', 39), ('ist', 3), ('ization', 2), ('ism', 2), (' Resources', 1)]\n",
      "17: [('istic', 30), ('ization', 3), ('ist', 3), ('ism', 2), (' Resources', 1)]\n",
      "18: [('istic', 33), ('ization', 4), ('ism', 3), ('ist', 3), ('izing', 2)]\n",
      "19: [('istic', 28), ('ization', 4), ('ism', 3), (' History', 2), ('ist', 2)]\n",
      "20: [('istic', 34), ('ization', 4), ('istically', 2), ('ism', 2), ('izing', 2)]\n",
      "21: [('istic', 27), ('ization', 3), (' History', 3), (' Intelligence', 2), ('izing', 2)]\n",
      "22: [('istic', 19), (' History', 4), (' Sciences', 3), (' Intelligence', 3), (' Creative', 2)]\n",
      "23: [('istic', 31), (' Creative', 3), (' Sciences', 3), (' Intelligence', 2), ('ist', 2)]\n",
      "24: [('istic', 48), (' Sciences', 5), (' sciences', 3), (' Creative', 3), ('ist', 2)]\n",
      "25: [('istic', 43), (' Sciences', 8), (' sciences', 6), ('ist', 2), (' Resources', 1)]\n",
      "26: [('istic', 37), (' Sciences', 15), (' sciences', 8), ('ist', 2), ('ized', 2)]\n",
      "27: [(' Sciences', 34), ('istic', 23), (' sciences', 12), (' Science', 2), (' Intelligence', 1)]\n",
      "28: [(' Sciences', 49), ('istic', 14), (' sciences', 11), (' Science', 2), ('ized', 1)]\n",
      "29: [(' Sciences', 50), ('istic', 15), (' sciences', 14), ('ized', 1), (' Science', 1)]\n",
      "30: [(' Sciences', 60), (' sciences', 16), ('istic', 9), ('rology', 1), (' Science', 1)]\n",
      "31: [(' Sciences', 64), (' sciences', 16), ('istic', 4), (' History', 2), (' Science', 1)]\n",
      "32: [(' Sciences', 59), (' sciences', 21), ('istic', 4), (' Science', 2), (' History', 2)]\n",
      "33: [(' Sciences', 50), (' sciences', 22), ('istic', 6), (' Science', 2), (' History', 2)]\n",
      "34: [(' Sciences', 35), (' sciences', 20), ('istic', 19), ('ized', 3), (' Science', 2)]\n",
      "35: [(' Sciences', 40), (' sciences', 17), ('istic', 11), (' History', 6), (' Science', 3)]\n",
      "36: [(' Sciences', 55), (' sciences', 16), ('istic', 9), (' Science', 4), (' History', 3)]\n",
      "37: [(' Sciences', 58), (' sciences', 11), (' Science', 5), (' History', 4), ('istic', 4)]\n",
      "38: [(' Sciences', 71), (' Science', 6), (' sciences', 5), (' Resources', 3), (' Language', 3)]\n",
      "39: [(' Sciences', 73), (' Science', 6), (' sciences', 5), (' Language', 3), (' Resources', 2)]\n",
      "40: [(' Sciences', 80), (' Science', 7), (' sciences', 5), (' Resources', 2), (' Language', 1)]\n",
      "41: [(' Sciences', 82), (' Science', 7), (' Resources', 3), (' sciences', 3), (' Language', 2)]\n",
      "42: [(' Sciences', 87), (' Science', 6), (' Language', 3), (' sciences', 2), (' Resources', 1)]\n",
      "43: [(' Sciences', 81), (' Science', 12), (' Language', 3), (' Resources', 1), (' sciences', 1)]\n",
      "44: [(' Sciences', 79), (' Science', 14), (' Language', 3), (' Resources', 1), (' sciences', 0)]\n",
      "45: [(' Sciences', 82), (' Science', 13), (' Language', 4), (' Resources', 0), (' Law', 0)]\n",
      "46: [(' Sciences', 84), (' Science', 14), (' Language', 2), (' Resources', 1), (' Environment', 0)]\n",
      "47: [(' Sciences', 98), (' Science', 2), (' Language', 1), (' Resources', 0), (' Environment', 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a prompt:  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "generate_interactive(model_new, tokenizer, max_out_len=30, use_logit_lens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2623f703-e4d3-4189-8d67-31d4e0bef19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model restored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a prompt:  Dr. Jon Rusert's research in Natural\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argument Model: [\"Dr. Jon Rusert's research in Natural Language Processing (NLP), particularly in areas related to adversarial attacks, has helped improve the robustness\"]\n",
      "\n",
      "--- Argument Model Logit Lens ---\n",
      "0: [('istic', 11), (' Natural', 11), ('orial', 3), (' gas', 3), ('ty', 2)]\n",
      "1: [('istic', 4), (' gas', 3), (' Natural', 2), (' Sounds', 1), (' Law', 1)]\n",
      "2: [('istic', 2), (' gas', 2), (' Law', 1), ('orial', 1), (' oils', 1)]\n",
      "3: [('istic', 5), (' Sounds', 2), (' Law', 2), (' oils', 1), (' gas', 1)]\n",
      "4: [('istic', 5), (' oils', 2), (' Sounds', 1), (' Law', 1), (' Natural', 1)]\n",
      "5: [('istic', 16), (' oils', 2), ('ization', 1), (' Sounds', 1), (' gas', 1)]\n",
      "6: [('istic', 26), (' oils', 1), (' Sounds', 1), (' gas', 1), (' Resources', 1)]\n",
      "7: [('istic', 24), (' Resources', 1), ('ist', 1), ('ization', 1), (' Sounds', 1)]\n",
      "8: [('istic', 26), (' Sounds', 2), (' Resources', 1), ('ization', 1), ('ist', 1)]\n",
      "9: [('istic', 26), (' Resources', 1), (' Sounds', 1), ('ization', 1), ('ist', 1)]\n",
      "10: [('istic', 32), ('ization', 2), ('ist', 2), (' Resources', 2), (' Sounds', 1)]\n",
      "11: [('istic', 27), (' Resources', 2), ('ization', 2), ('ist', 1), ('ities', 1)]\n",
      "12: [('istic', 28), (' Resources', 2), ('ization', 2), ('ist', 1), ('ized', 1)]\n",
      "13: [('istic', 37), (' Resources', 2), ('ist', 2), ('ism', 1), ('ization', 1)]\n",
      "14: [('istic', 31), ('ist', 2), (' Resources', 2), ('ization', 2), ('ism', 1)]\n",
      "15: [('istic', 28), ('ization', 2), ('ist', 2), (' Resources', 1), ('ism', 1)]\n",
      "16: [('istic', 39), ('ist', 3), ('ization', 2), ('ism', 2), (' Resources', 1)]\n",
      "17: [('istic', 30), ('ization', 3), ('ist', 3), ('ism', 2), (' Resources', 1)]\n",
      "18: [('istic', 30), ('ization', 6), ('ism', 4), ('ist', 3), ('izing', 2)]\n",
      "19: [('istic', 29), ('ization', 4), ('ism', 4), ('ist', 3), ('istically', 2)]\n",
      "20: [('istic', 35), ('istically', 4), ('ization', 4), ('ism', 3), ('ist', 2)]\n",
      "21: [('istic', 39), ('ization', 5), ('istically', 4), ('ist', 2), (' Resources', 2)]\n",
      "22: [('istic', 29), (' Resources', 4), ('istically', 3), ('ization', 3), (' History', 2)]\n",
      "23: [('istic', 35), (' Resources', 5), ('istically', 3), ('ist', 2), ('ization', 2)]\n",
      "24: [('istic', 53), ('ist', 3), ('istically', 2), (' Resources', 2), (' Sciences', 2)]\n",
      "25: [('istic', 43), (' Resources', 4), (' sciences', 3), (' Sciences', 3), ('ist', 2)]\n",
      "26: [('istic', 33), (' Sciences', 10), (' sciences', 6), (' Resources', 2), ('izing', 2)]\n",
      "27: [('istic', 27), (' Sciences', 21), (' sciences', 9), (' Resources', 3), (' Science', 3)]\n",
      "28: [(' Sciences', 31), ('istic', 22), (' sciences', 9), (' Resources', 4), (' Science', 2)]\n",
      "29: [(' Sciences', 31), ('istic', 27), (' sciences', 10), ('istically', 2), ('ized', 2)]\n",
      "30: [(' Sciences', 41), ('istic', 18), (' sciences', 14), (' Resources', 3), ('rology', 3)]\n",
      "31: [(' Sciences', 47), (' sciences', 11), ('istic', 11), (' Resources', 3), (' Science', 2)]\n",
      "32: [(' Sciences', 44), (' sciences', 18), ('istic', 9), (' Resources', 3), (' Science', 3)]\n",
      "33: [(' Sciences', 33), ('istic', 19), (' sciences', 13), (' Language', 4), ('ized', 3)]\n",
      "34: [('istic', 43), (' Sciences', 15), (' sciences', 7), ('ized', 4), (' Language', 3)]\n",
      "35: [('istic', 27), (' Sciences', 17), (' Language', 11), (' sciences', 5), (' History', 4)]\n",
      "36: [(' Language', 24), (' Sciences', 20), ('istic', 19), (' Resource', 6), (' sciences', 4)]\n",
      "37: [(' Language', 48), (' Sciences', 14), ('istic', 5), (' Resource', 5), (' History', 4)]\n",
      "38: [(' Language', 49), (' Sciences', 16), (' Resource', 7), ('istic', 5), (' Science', 4)]\n",
      "39: [(' Language', 61), (' Sciences', 11), (' Science', 4), (' Resources', 4), ('istic', 3)]\n",
      "40: [(' Language', 60), (' Sciences', 17), (' Science', 6), (' Resources', 4), (' language', 2)]\n",
      "41: [(' Language', 69), (' Sciences', 12), (' Science', 5), (' Resources', 4), (' language', 2)]\n",
      "42: [(' Language', 87), (' Sciences', 6), (' Science', 3), (' language', 2), (' Resources', 1)]\n",
      "43: [(' Language', 86), (' Sciences', 5), (' Science', 4), (' Resources', 1), (' language', 1)]\n",
      "44: [(' Language', 89), (' Sciences', 4), (' Science', 3), (' Resources', 1), (' language', 1)]\n",
      "45: [(' Language', 96), (' Sciences', 2), (' Science', 1), (' Resources', 0), (' Resource', 0)]\n",
      "46: [(' Language', 98), (' Sciences', 1), (' Science', 1), (' Resources', 0), (' Resource', 0)]\n",
      "47: [(' Language', 99), (' Sciences', 0), (' Languages', 0), (' Resources', 0), (' Science', 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Restore fresh copy of model\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for k, v in orig_weights.items():\n",
    "            nethook.get_parameter(model, k)[...] = v\n",
    "    print(\"Original model restored\")\n",
    "except NameError as e:\n",
    "    print(f\"No model weights to restore: {e}\")\n",
    "\n",
    "generate_interactive(model, tokenizer, max_out_len=30, use_logit_lens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292117e-bf5d-48d7-a193-8cae74e298b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3.9 (Default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
